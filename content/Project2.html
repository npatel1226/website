---
title: "Project 2"
author: "Neha Patel"
date: 2019-11-20
output:
  html_document: default
  pdf_document: default
---



<div id="r-markdown" class="section level2">
<h2>R Markdown</h2>
<p>This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <a href="http://rmarkdown.rstudio.com" class="uri">http://rmarkdown.rstudio.com</a>.</p>
<p>When you click the <strong>Knit</strong> button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:</p>
</div>
<div id="dataset" class="section level1">
<h1>0. Dataset</h1>
<pre class="r"><code>data(package = .packages(all.available = TRUE))</code></pre>
<pre><code>## Warning in data(package = .packages(all.available = TRUE)): datasets have
## been moved from package &#39;base&#39; to package &#39;datasets&#39;</code></pre>
<pre><code>## Warning in data(package = .packages(all.available = TRUE)): datasets have
## been moved from package &#39;stats&#39; to package &#39;datasets&#39;</code></pre>
<pre class="r"><code>library(hexbin)
data(NHANES)
library(dplyr)</code></pre>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<pre class="r"><code>library(&quot;devtools&quot;)</code></pre>
<pre><code>## Loading required package: usethis</code></pre>
<pre class="r"><code>library(&quot;pipeR&quot;)
library(&quot;tidyverse&quot;)</code></pre>
<pre><code>## ── Attaching packages ──────────────────────────────────────────────── tidyverse 1.2.1 ──</code></pre>
<pre><code>## ✔ ggplot2 3.2.1     ✔ readr   1.3.1
## ✔ tibble  2.1.3     ✔ purrr   0.3.3
## ✔ tidyr   1.0.0     ✔ stringr 1.4.0
## ✔ ggplot2 3.2.1     ✔ forcats 0.4.0</code></pre>
<pre><code>## ── Conflicts ─────────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>library(&quot;tidyr&quot;)
NHANES1&lt;-na.omit(NHANES)</code></pre>
<p>I used the dataset NHANES (National Health and Nutrition Examination Survey). I used the variables Cancer.Incidence (categorical and binary), Age (numeric), BMI (numeric), and Hemoglobin (numeric). I wanted to determine if Age, BMI, Race, and Hemoglobin had an impact or not the chances of cancer occuring.</p>
</div>
<div id="manova" class="section level1">
<h1>1. MANOVA</h1>
<pre class="r"><code>man1&lt;-manova(cbind(Age,BMI, Race, Hemoglobin)~Cancer.Incidence, data=NHANES1)
summary(man1)</code></pre>
<pre><code>##                    Df  Pillai approx F num Df den Df    Pr(&gt;F)    
## Cancer.Incidence    1 0.06246   48.133      4   2890 &lt; 2.2e-16 ***
## Residuals        2893                                             
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary.aov(man1)</code></pre>
<pre><code>##  Response Age :
##                    Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## Cancer.Incidence    1  41257   41257  189.87 &lt; 2.2e-16 ***
## Residuals        2893 628622     217                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
##  Response BMI :
##                    Df Sum Sq Mean Sq F value  Pr(&gt;F)  
## Cancer.Incidence    1     67  66.886  3.8974 0.04846 *
## Residuals        2893  49650  17.162                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
##  Response Race :
##                    Df Sum Sq Mean Sq F value Pr(&gt;F)
## Cancer.Incidence    1   0.14 0.14263   1.065 0.3022
## Residuals        2893 387.45 0.13393               
## 
##  Response Hemoglobin :
##                    Df Sum Sq Mean Sq F value Pr(&gt;F)  
## Cancer.Incidence    1    9.2  9.2120   6.177  0.013 *
## Residuals        2893 4314.4  1.4913                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>NHANES1%&gt;%group_by(Cancer.Incidence)%&gt;%summarize(mean(Age), mean(BMI), mean(Race), mean(Hemoglobin))</code></pre>
<pre><code>## # A tibble: 2 x 5
##   Cancer.Incidence `mean(Age)` `mean(BMI)` `mean(Race)` `mean(Hemoglobin)`
##   &lt;fct&gt;                  &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;              &lt;dbl&gt;
## 1 No                      50.6        25.9        0.843               15.5
## 2 Yes                     62.6        25.4        0.821               15.3</code></pre>
<p>When cancer was not present, the mean age difference was 50.6, the mean BMI difference was 25.9, mean Race difference was 0.8, and mean Hemoglobin difference was 15.5. When cancer did occur, the mean age difference was 62.6, the mean BMI difference was 25.4, mean Race difference was 0.8, and mean Hemoglobin difference was 15.3. There is not a very large difference in the mean differences for these variables when cancer occurs and does not occur. MANOVA was conducted to determine the effects of Age, BMI, Race, and Hemoglobin levels on Cancer Incidence and see if they differ from each other based on if cancer was present or not. The Pillai trace was 0.062, F(4,2890)=48.13, p&lt;2.2e-16. The MANOVA indicated significant univariate; the univariate ANOVAs were significant for Age (F(1,2893)=189.87 while p&lt;2.2e-16), BMI (F(1,2893)=3.89 while p=0.048), and Hemoblobin (F(1,2893)=6.177 while p=0.013), but not for Race (F(1,2893)=1.065 while p=0.3022). There were a total of 5 tests that were ran, becuase only 1 MANOVA was ran with 1 categorical variable that had 2 levels and 4 numeric variables. The probability of making a type 1 error is 1-(0.95^5)=0.2262191, so the Boneferroni adjusted significance level is 0.2262191/5=0.04524382. Thus, the variable Race is not significant. Assumptions include having multivariate normality betweeen dependent variables, equal covariance between them, and no multicollinearility. They are not likely to have been met, since these variables do not seem to be correlated with each other.</p>
<p>#2. Randomization Test</p>
<pre class="r"><code>t.test(data=NHANES1,Age~Cancer.Incidence)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  Age by Cancer.Incidence
## t = -19.609, df = 556.63, p-value &lt; 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -13.17379 -10.77482
## sample estimates:
##  mean in group No mean in group Yes 
##          50.59977          62.57407</code></pre>
<pre class="r"><code>t.test(data=NHANES1, BMI~Cancer.Incidence)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  BMI by Cancer.Incidence
## t = 2.0873, df = 422.69, p-value = 0.03746
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.02810446 0.93616654
## sample estimates:
##  mean in group No mean in group Yes 
##          25.90930          25.42716</code></pre>
<pre class="r"><code>t.test(data=NHANES1,Race~Cancer.Incidence)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  Race by Cancer.Incidence
## t = 0.98933, df = 399.51, p-value = 0.3231
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.02197737  0.06650537
## sample estimates:
##  mean in group No mean in group Yes 
##         0.8432517         0.8209877</code></pre>
<pre class="r"><code>t.test(data=NHANES1,Hemoglobin~Cancer.Incidence)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  Hemoglobin by Cancer.Incidence
## t = 2.3025, df = 392.77, p-value = 0.02183
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.02614596 0.33170947
## sample estimates:
##  mean in group No mean in group Yes 
##          15.51813          15.33920</code></pre>
<pre class="r"><code>t&lt;-vector()
for(i in 1:10000){
  samp&lt;-rnorm(25,mean=5)
  t[i] &lt;- (mean(samp)-5)/(sd(samp)/sqrt(25))
}
data.frame(t)%&gt;%
ggplot(aes(t))+geom_histogram(aes(y=..density..), bins=30)+
  stat_function(fun=dt,args=list(df=24),geom=&quot;line&quot;) +geom_abline(col=&quot;red&quot;)</code></pre>
<p><img src="/Project2_files/figure-html/unnamed-chunk-3-1.png" width="672" />
Independent-sample t tests were conducted for comparision. Null hypotheis is that the true difference in means is equal to 0. The alternative hypothesis is the true difference in means is not equal to 0. According to the test results, the p-value is significant for Age and BMI so we reject the null hypothesis for both and conclude that the true differnce in means is not equal to 0 between age and cancer incidence and between BMI and cancer incidence. The means of the two samples are signifincantly different. On the other hand, the p-value is not significant for Race and Hemoglobin so we accept the null hypothesis and conclude that the true difference in their means is equal to 0. The plot shows a null distribution where the mean difference is 0.</p>
<p>#3. Linear Regression Model</p>
<pre class="r"><code>NHANES1$Hemoglobin_c&lt;- NHANES1$Hemoglobin-mean(NHANES1$Hemoglobin)
NHANES1$BMI_c &lt;- NHANES1$BMI-mean(NHANES1$BMI)
fit &lt;-lm(Hemoglobin_c ~ BMI_c * Cancer.Incidence, data = NHANES1)
summary(fit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Hemoglobin_c ~ BMI_c * Cancer.Incidence, data = NHANES1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.6596 -0.7570  0.0174  0.7627  4.2068 
## 
## Coefficients:
##                            Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                0.018128   0.023906   0.758   0.4483    
## BMI_c                      0.035158   0.005728   6.138  9.5e-10 ***
## Cancer.IncidenceYes       -0.155754   0.071839  -2.168   0.0302 *  
## BMI_c:Cancer.IncidenceYes  0.014532   0.018281   0.795   0.4267    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.212 on 2891 degrees of freedom
## Multiple R-squared:  0.01772,    Adjusted R-squared:  0.0167 
## F-statistic: 17.38 on 3 and 2891 DF,  p-value: 3.499e-11</code></pre>
<pre class="r"><code>ggplot(NHANES1, aes(x=Hemoglobin, y=BMI,group=Cancer.Incidence))+geom_point(aes(color=Cancer.Incidence))+
 geom_smooth(method=&quot;lm&quot;,formula=y~1,se=F,fullrange=T,aes(color=Cancer.Incidence))+theme(legend.position=c(.9,.19))+xlab(&quot;Age&quot;)</code></pre>
<p><img src="/Project2_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code>#linearity, homoskedasticity 
resids&lt;-fit$residuals
fitvals&lt;-fit$fitted.values
ggplot()+geom_point(aes(fitvals,resids))+geom_hline(yintercept=0, color=&#39;red&#39;)</code></pre>
<p><img src="/Project2_files/figure-html/unnamed-chunk-4-2.png" width="672" /></p>
<pre class="r"><code>#normality 
ggplot()+geom_histogram(aes(resids), bins=20)</code></pre>
<p><img src="/Project2_files/figure-html/unnamed-chunk-4-3.png" width="672" /></p>
<pre class="r"><code>#robust SE
library(lmtest)</code></pre>
<pre><code>## Loading required package: zoo</code></pre>
<pre><code>## 
## Attaching package: &#39;zoo&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     as.Date, as.Date.numeric</code></pre>
<pre class="r"><code>library(sandwich)
coeftest(fit, vcov=vcovHC(fit))[,1:2]</code></pre>
<pre><code>##                              Estimate  Std. Error
## (Intercept)                0.01812795 0.023632311
## BMI_c                      0.03515848 0.006491887
## Cancer.IncidenceYes       -0.15575423 0.077913783
## BMI_c:Cancer.IncidenceYes  0.01453217 0.022217591</code></pre>
<pre class="r"><code>#proportion of variation explained by model
summary(fit)$r.sq</code></pre>
<pre><code>## [1] 0.0177154</code></pre>
<pre class="r"><code>#likelihood ratio test
model1 &lt;- lm(Hemoglobin_c ~ Cancer.Incidence,data = NHANES1)
model2 &lt;- lm(BMI_c ~ Cancer.Incidence,data = NHANES1)
lrtest (model1, model2)</code></pre>
<pre><code>## Likelihood ratio test
## 
## Model 1: Hemoglobin_c ~ Cancer.Incidence
## Model 2: BMI_c ~ Cancer.Incidence
##   #Df  LogLik Df  Chisq Pr(&gt;Chisq)    
## 1   3 -4685.4                         
## 2   3 -8221.6  0 7072.5  &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Controlling for Hemoglobin, there is significant effect of BMI on cancer incidence. For every one unit increase in Hemoglobin, cancer incidence increases by 0.03.The intercept value explains Hemoglobin when Cancer Incidence and BMI is 0. Having cancer will decrease your Hemoglobin levels by 0.155 compared to when you don’t have cancer. The interaction explains if the effect of Hemoglobin levels on BMI differs by cancer incidence. All assumptions are not met because the plots for linearity and homoskedasticity are not normal. Points are clustered rather than spread. The plot for normality meets the assumtpion of normal distribution however is still skewed to one side over another. There was no difference in regression results with robust standard errors.This model explains 0.0177154 of of the variation in the outcome. The likelihood ratio test also shows significance of BMI on Cancer incidence.</p>
<p>#4. Regression Model with Bootstrapped Standard Errors</p>
<pre class="r"><code>fit &lt;-lm(Hemoglobin_c ~ BMI_c * Cancer.Incidence, data = NHANES1)
summary(fit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Hemoglobin_c ~ BMI_c * Cancer.Incidence, data = NHANES1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.6596 -0.7570  0.0174  0.7627  4.2068 
## 
## Coefficients:
##                            Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                0.018128   0.023906   0.758   0.4483    
## BMI_c                      0.035158   0.005728   6.138  9.5e-10 ***
## Cancer.IncidenceYes       -0.155754   0.071839  -2.168   0.0302 *  
## BMI_c:Cancer.IncidenceYes  0.014532   0.018281   0.795   0.4267    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.212 on 2891 degrees of freedom
## Multiple R-squared:  0.01772,    Adjusted R-squared:  0.0167 
## F-statistic: 17.38 on 3 and 2891 DF,  p-value: 3.499e-11</code></pre>
<pre class="r"><code>#boostrap residuals 
 resids&lt;-fit$residuals 
 fitted&lt;-fit$fitted.values 
 resid_resamp&lt;-replicate(5000,{
 new_resids&lt;-sample(resids,replace=TRUE) 
 NHANES1$new_y&lt;-fitted+new_resids 
 fit1&lt;-lm(new_y~Hemoglobin_c*BMI_c+Cancer.Incidence,data=NHANES1) 
 coef(fit1) 
})
 resid_resamp%&gt;%t%&gt;%as.data.frame%&gt;%summarize_all(sd)</code></pre>
<pre><code>##   (Intercept) Hemoglobin_c       BMI_c Cancer.IncidenceYes
## 1  0.02410599   0.01858575 0.005543378          0.07137479
##   Hemoglobin_c:BMI_c
## 1        0.004214055</code></pre>
<p>Bootstrapping uses resampling from the data in order to determine the sampling distribution of an estimate. There are significant differences in SEs and p-values compared to the original values. The intercept increased to 0.018128.</p>
<p>#5. Logistic Regression</p>
<pre class="r"><code>library(tidyverse); library(MASS); library(lmtest); library(microbenchmark)</code></pre>
<pre><code>## 
## Attaching package: &#39;MASS&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     select</code></pre>
<pre class="r"><code>class_diag&lt;-function(probs,truth){
  tab&lt;-table(factor(probs&gt;.5,levels=c(&quot;FALSE&quot;,&quot;TRUE&quot;)),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]
  if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE) truth&lt;-as.numeric(truth)-1
  
  ord&lt;-order(probs, decreasing=TRUE)
  probs &lt;- probs[ord]; truth &lt;- truth[ord]
  TPR=cumsum(truth)/max(1,sum(truth))
  FPR=cumsum(!truth)/max(1,sum(!truth))
  dup&lt;-c(probs[-1]&gt;=probs[-length(probs)], FALSE)
  TPR&lt;-c(0,TPR[!dup],1); FPR&lt;-c(0,FPR[!dup],1)
  n &lt;- length(TPR)
  auc&lt;- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
  data.frame(acc,sens,spec,ppv,auc)
}

fit2&lt;-glm(Cancer.Incidence ~ Age+ BMI + Hemoglobin + Race, data= NHANES1, family =&quot;binomial&quot;) 
coeftest(fit2)</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##               Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept) -5.3979832  0.9061103 -5.9573 2.564e-09 ***
## Age          0.0657215  0.0054397 12.0819 &lt; 2.2e-16 ***
## BMI         -0.0216416  0.0157263 -1.3761    0.1688    
## Hemoglobin   0.0113898  0.0498380  0.2285    0.8192    
## Race        -0.0660138  0.1649235 -0.4003    0.6890    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>prob&lt;- predict(fit2, type = &quot;response&quot;)
class_diag(prob, NHANES1$Cancer.Incidence)</code></pre>
<pre><code>##           acc sens spec ppv       auc
## Yes 0.8880829    0    1 NaN 0.7251508</code></pre>
<pre class="r"><code>table(predict = as.numeric(prob&gt;0.5), truth = NHANES1$Cancer.Incidence)%&gt;%addmargins</code></pre>
<pre><code>##        truth
## predict   No  Yes  Sum
##     0   2571  324 2895
##     Sum 2571  324 2895</code></pre>
<pre class="r"><code>ggplot(NHANES1, aes(Age+ BMI + Hemoglobin + Race, prob))+ geom_point(aes(color = Cancer.Incidence), alpha = .5, size =.3) + geom_rug(aes(color = Cancer.Incidence), sides = &quot;right&quot;) + geom_hline(yintercept = .5)</code></pre>
<p><img src="/Project2_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code>##ROC Curve
sens&lt;- function(p, data = NHANES1, y = Cancer.Incidence) 
mean(NHANES1[NHANES1$Cancer.Incidence==1,]$prob&gt;p) 

spec&lt;- function(p,data=NHANES1, y=Cancer.Incidence) 
mean(NHANES1[NHANES1$Cancer.Incidence==0,]$prob&lt;p)

sensitivity&lt;- sapply(seq(0,1,.01), sens, NHANES1)
specificity&lt;- sapply(seq(0,1,.01), spec, NHANES1)

ROC1&lt;- data.frame(sensitivity, specificity, cutoff = seq(0,1,.01))
ROC1$TPR&lt;- sensitivity
ROC1$FPR&lt;- 1- specificity
ROC1%&gt;%ggplot(aes(FPR, TPR))+geom_path(size = 1.5) + geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1), lty = 2) + scale_x_continuous(limits = c(0,1))</code></pre>
<pre><code>## Warning: Removed 101 rows containing missing values (geom_path).</code></pre>
<p><img src="/Project2_files/figure-html/unnamed-chunk-6-2.png" width="672" /></p>
<pre class="r"><code>library(plotROC)
ROCplot&lt;-ggplot(NHANES1)+geom_roc(aes(d=Cancer.Incidence,m=Age+ BMI + Hemoglobin + Race), n.cuts=0) 
calc_auc(ROCplot)</code></pre>
<pre><code>## Warning in verify_d(data$d): D not labeled 0/1, assuming No = 0 and Yes =
## 1!</code></pre>
<pre><code>##   PANEL group      AUC
## 1     1    -1 0.711508</code></pre>
<pre class="r"><code>odds&lt;-function(p)p/(1-p)
p&lt;-seq(0,1,by=.1)
cbind(p, odds=odds(p))%&gt;%round(4)</code></pre>
<pre><code>##         p   odds
##  [1,] 0.0 0.0000
##  [2,] 0.1 0.1111
##  [3,] 0.2 0.2500
##  [4,] 0.3 0.4286
##  [5,] 0.4 0.6667
##  [6,] 0.5 1.0000
##  [7,] 0.6 1.5000
##  [8,] 0.7 2.3333
##  [9,] 0.8 4.0000
## [10,] 0.9 9.0000
## [11,] 1.0    Inf</code></pre>
<pre class="r"><code>logit&lt;-function(p)log(odds(p))
cbind(p, odds=odds(p),logit=logit(p))%&gt;%round(4)</code></pre>
<pre><code>##         p   odds   logit
##  [1,] 0.0 0.0000    -Inf
##  [2,] 0.1 0.1111 -2.1972
##  [3,] 0.2 0.2500 -1.3863
##  [4,] 0.3 0.4286 -0.8473
##  [5,] 0.4 0.6667 -0.4055
##  [6,] 0.5 1.0000  0.0000
##  [7,] 0.6 1.5000  0.4055
##  [8,] 0.7 2.3333  0.8473
##  [9,] 0.8 4.0000  1.3863
## [10,] 0.9 9.0000  2.1972
## [11,] 1.0    Inf     Inf</code></pre>
<pre class="r"><code>NHANES1$logit&lt;-predict(fit2) #get predicted log-odds
NHANES1$outcome&lt;-factor(NHANES1$Cancer.Incidence,levels=c(&quot;Yes&quot;,&quot;No&quot;))
ggplot(NHANES1,aes(logit, fill=as.factor(Cancer.Incidence)))+geom_density(alpha=.3)+
geom_vline(xintercept=0,lty=2)</code></pre>
<p><img src="/Project2_files/figure-html/unnamed-chunk-6-3.png" width="672" /></p>
<pre class="r"><code>#10 fold CV


set.seed(1234) 
k = 10
data1 &lt;- NHANES1[sample(nrow(NHANES1)), ]
folds &lt;- cut(seq(1:nrow(NHANES1)), breaks = k, labels = F) 
diag &lt;- NULL
for (i in 1:k) {
  train &lt;- data1[folds != i, ]
  test &lt;- data1[folds == i, ]
  truth &lt;- test$Cancer.Incidence
  fit4 &lt;- glm(Cancer.Incidence ~ Age+ BMI + Hemoglobin + Race , data = train, family = &quot;binomial&quot;) 
  probs &lt;- predict(fit4, newdata = test, type = &quot;response&quot;) 
  preds &lt;- ifelse(probs &gt; 0.5, 1, 0)
  diags &lt;- rbind(diag, class_diag(probs, truth)) 
}
diags %&gt;% summarize_all(mean)</code></pre>
<pre><code>##         acc sens spec ppv       auc
## 1 0.8896552    0    1 NaN 0.7621124</code></pre>
<pre class="r"><code>summary(fit4)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Cancer.Incidence ~ Age + BMI + Hemoglobin + Race, 
##     family = &quot;binomial&quot;, data = train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.9046  -0.6068  -0.3623  -0.2230   2.8342  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -4.972782   0.951291  -5.227 1.72e-07 ***
## Age          0.063326   0.005654  11.201  &lt; 2e-16 ***
## BMI         -0.019470   0.016795  -1.159    0.246    
## Hemoglobin  -0.004970   0.052425  -0.095    0.924    
## Race        -0.164710   0.170267  -0.967    0.333    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1828.0  on 2604  degrees of freedom
## Residual deviance: 1651.7  on 2600  degrees of freedom
## AIC: 1661.7
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>Interaction between age and cancer incidence is significant. For no cancer, odds for agre are 0.00618 while for incidence of cancer, log odds are 1.0677 times while for cancer, odds for age are 0.00659.Confusion matrix shows the model predictions against the true values. For this model, Accuracy is 0.888, Sensitivity is 0, Specificity is 1, Precision was NaN, and AUC was 0.725.An ROC curve shows Sensitivity would be 1 while Specificity would be 0. AUC resulting from the curve is 0.711, which is less than that of the confusion matrix. A 10 fold cross validation was done to divide the dataset and perform a test on a proportion of it a repreasted number of times. The Accuracy is 0.888,Sensitivity is 0, Specificity is 1, Precision s NaN, and AUC is 0.7208. The accuracy, sensitivity, specificity, and precision remained the same; AUC was also very similar, but decreased slightly.</p>
<p>#6. LASSO Regression</p>
<pre class="r"><code>library(glmnet)</code></pre>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## 
## Attaching package: &#39;Matrix&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:tidyr&#39;:
## 
##     expand, pack, unpack</code></pre>
<pre><code>## Loaded glmnet 3.0-1</code></pre>
<pre class="r"><code>y &lt;- as.matrix(NHANES1$Cancer.Incidence)
x&lt;-NHANES1%&gt;%dplyr::select(Age,BMI, Hemoglobin,Race, Weight,Diet.Iron,Transferin)%&gt;%mutate_all(scale)%&gt;%as.matrix
cv1 &lt;- cv.glmnet(x, y, family = &quot;binomial&quot;)
lasso1 &lt;- glmnet(x, y, family = &quot;binomial&quot;, lambda = cv1$lambda.1se) 
coef(lasso1)</code></pre>
<pre><code>## 8 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                     s0
## (Intercept) -2.1459726
## Age          0.4461873
## BMI          .        
## Hemoglobin   .        
## Race         .        
## Weight       .        
## Diet.Iron    .        
## Transferin   .</code></pre>
<pre class="r"><code>set.seed(1234)
k=10 
data2&lt;-NHANES1[sample(nrow(NHANES1)),] 
folds&lt;-cut(seq(1:nrow(NHANES1)),breaks=k,labels=F) 
diags&lt;-NULL
for(i in 1:k){
  train&lt;-data2[folds!=i,]
  test&lt;-data2[folds==i,]
  truth&lt;-test$Cancer.Incidence
  fit5&lt;-glm(Cancer.Incidence~Age,data=NHANES1,family=&quot;binomial&quot;)
  probs&lt;-predict(fit5,newdata = test,type=&quot;response&quot;)
  diags&lt;-rbind(diags,class_diag(probs,truth))
}

 apply(diags,2,mean)</code></pre>
<pre><code>##       acc      sens      spec       ppv       auc 
## 0.8880838 0.0000000 1.0000000       NaN 0.7213482</code></pre>
<pre class="r"><code>summary(fit5)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Cancer.Incidence ~ Age, family = &quot;binomial&quot;, data = NHANES1)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.8263  -0.6179  -0.3640  -0.2170   2.8352  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -5.849149   0.337541  -17.33   &lt;2e-16 ***
## Age          0.066000   0.005384   12.26   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 2029.4  on 2894  degrees of freedom
## Residual deviance: 1826.7  on 2893  degrees of freedom
## AIC: 1830.7
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>Only the variable age is retained after doing a LASSO regression, which means that it is the only significant predictor of Cancer.Incidence amongst all the other variables. Although the AUC slightly decreased, the accuracy remained the same compared to the logistic regression in part 5.</p>
</div>
